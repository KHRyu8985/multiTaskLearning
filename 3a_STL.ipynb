{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b76725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import fastmri\n",
    "from fastmri.data import transforms\n",
    "from fastmri.models.unet import Unet\n",
    "from fastmri.models.varnet import *\n",
    "\n",
    "import sigpy as sp\n",
    "from sigpy import from_pytorch\n",
    "import sigpy.plot as pl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "import skimage.metrics\n",
    "\n",
    "from dloader import genDataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed139960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # command line argument parser\n",
    "# parser = argparse.ArgumentParser(\n",
    "#     description = 'define parameters and roots for STL training'\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--scarcities', default=[0, 1], type=int, nargs='+',\n",
    "#     help='number of samples will be decreased by 1/2^N; match with roots'\n",
    "#     )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--undersample', default=[6], type=int, nargs='+',\n",
    "#     help='undersampling factor of k-space'\n",
    "#     )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--dataroots', nargs='+',\n",
    "#     help='paths of data files; match with scarcities',\n",
    "# #     required = True\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--epochs', default=100, type=int,\n",
    "#     help='number of epochs to run'\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--lr', default=0.001, type=float,\n",
    "#     help='learning rate'\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--modelpath', default='models/best-no-name.pt',\n",
    "#     help='path to save best model'\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--verbose', default=True, type=bool,\n",
    "#     help='''if true, prints to console and creatues full TensorBoard\n",
    "#     (if tensorboard is also True)'''\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--tensorboard', default=True, type=bool,\n",
    "#     help='if true, creates TensorBoard'\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--savefreq', default=5, type=int,\n",
    "#     help='how many epochs per saved recon image'\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     '--experimentname', default='unnamed_experiment',\n",
    "#     help='experiment name'\n",
    "# )\n",
    "\n",
    "\n",
    "# opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffef36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make one iteration block like this\n",
    "class VarNetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    This model applies a combination of soft data consistency with the input\n",
    "    model as a regularizer. A series of these blocks can be stacked to form\n",
    "    the full variational network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: Module for \"regularization\" component of variational\n",
    "                network.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.eta = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def sens_expand(self, x: torch.Tensor, sens_maps: torch.Tensor) -> torch.Tensor:\n",
    "        return fastmri.fft2c(fastmri.complex_mul(x, sens_maps)) # F*S operator\n",
    "\n",
    "    def sens_reduce(self, x: torch.Tensor, sens_maps: torch.Tensor) -> torch.Tensor:\n",
    "        x = fastmri.ifft2c(x)\n",
    "        return fastmri.complex_mul(x, fastmri.complex_conj(sens_maps)).sum(\n",
    "            dim=1, keepdim=True\n",
    "        ) # S^H * F^H operator\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        current_kspace: torch.Tensor,\n",
    "        ref_kspace: torch.Tensor,\n",
    "        mask: torch.Tensor,\n",
    "        sens_maps: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        mask = mask.bool()\n",
    "        zero = torch.zeros(1, 1, 1, 1, 1).to(current_kspace)\n",
    "        soft_dc = torch.where(mask, current_kspace - ref_kspace, zero) * self.eta\n",
    "        model_term = self.sens_expand(\n",
    "            self.model(self.sens_reduce(current_kspace, sens_maps)), sens_maps\n",
    "        )\n",
    "\n",
    "        return current_kspace - soft_dc - model_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e7d9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can stack VarNetBlocks to make a unrolled VarNet (with 10 blocks)\n",
    "\n",
    "\n",
    "class VarNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A full variational network model.\n",
    "\n",
    "    This model applies a combination of soft data consistency with a U-Net\n",
    "    regularizer. To use non-U-Net regularizers, use VarNetBock.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_cascades: int = 12,\n",
    "        chans: int = 18,\n",
    "        pools: int = 4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cascades = nn.ModuleList(\n",
    "            [VarNetBlock(NormUnet(chans, pools)) for _ in range(num_cascades)]\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        masked_kspace: torch.Tensor, \n",
    "        mask: torch.Tensor,\n",
    "        sens_maps: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        kspace_pred = masked_kspace.clone()\n",
    "\n",
    "        for cascade in self.cascades:\n",
    "            kspace_pred = cascade(kspace_pred, masked_kspace, mask, sens_maps)\n",
    "        \n",
    "        im_coil = fastmri.ifft2c(kspace_pred)\n",
    "        im_comb = fastmri.complex_mul(im_coil, fastmri.complex_conj(sens_maps)).sum(\n",
    "            dim=1, keepdim=True\n",
    "        )\n",
    "        \n",
    "        return kspace_pred, im_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486cf77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def test_result(im_fs: torch.Tensor, im_us: torch.Tensor) -> np.ndarray:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        im_us = from_pytorch(im_us.cpu().detach(),iscomplex = True)\n",
    "        im_fs = from_pytorch(im_fs.cpu().detach(), iscomplex = True)\n",
    "        im_us = np.abs(im_us).squeeze()\n",
    "        im_fs = np.abs(im_fs).squeeze()\n",
    "        \n",
    "        im_us = sp.resize(im_us, [360, 320])\n",
    "        im_fs = sp.resize(im_fs, [360, 320])\n",
    "        \n",
    "        out_cat = np.concatenate((im_us, im_fs),1)\n",
    "        error_cat = np.concatenate((im_us, im_us),1)\n",
    "        error_cat = np.abs(error_cat - out_cat) * 5\n",
    "        \n",
    "        out_cat = np.concatenate((error_cat, out_cat,), axis=0)\n",
    "        out_cat = out_cat * 20\n",
    "        \n",
    "    return np.flip(out_cat)\n",
    "\n",
    "\n",
    "def plot_quadrant(im_fs, im_us):\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(test_result(im_fs, im_us), cmap = 'gray')\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def param_dict(lr, epochs, undersampling, scarcities, center_fractions):\n",
    "    params = {}\n",
    "    params['lr'] = lr\n",
    "    params['epochs'] = epochs\n",
    "    \n",
    "    for i in range(len(undersampling)):\n",
    "        params[f'accerlation_{i}'] = undersampling[i]\n",
    "    \n",
    "    for i in range(len(scarcities)):\n",
    "        params[f'scarcity_{i}'] = scarcities[i]\n",
    "        \n",
    "    for i in range(len(center_fractions)):\n",
    "        params[f'center_fraction_{i}'] = center_fractions[i]\n",
    "    return params\n",
    "\n",
    "\n",
    "def write_tensorboard(avg_cost, model, total_epochs, opt):            \n",
    "    #write to tensorboard ###opt###\n",
    "    contrast_1, contrast_2, _ = avg_cost.keys()\n",
    "    for epoch in range(total_epochs):\n",
    "        \n",
    "        writer.add_scalars(\n",
    "            'losses/l1', {\n",
    "                f'train/{contrast_1}' : avg_cost[contrast_1][epoch, 0],\n",
    "                f'val/{contrast_1}' : avg_cost[contrast_1][epoch, 4],\n",
    "                f'train/{contrast_2}' : avg_cost[contrast_2][epoch, 0],\n",
    "                f'val/{contrast_2}' : avg_cost[contrast_2][epoch, 4],\n",
    "            }, \n",
    "            epoch\n",
    "        )\n",
    "\n",
    "        writer.add_scalars(\n",
    "            'metrics/ssim', {\n",
    "                f'train/{contrast_1}' : avg_cost[contrast_1][epoch, 1],\n",
    "                f'val/{contrast_1}' : avg_cost[contrast_1][epoch, 5],\n",
    "                f'train/{contrast_2}' : avg_cost[contrast_2][epoch, 1],\n",
    "                f'val/{contrast_2}' : avg_cost[contrast_2][epoch, 5],\n",
    "            }, \n",
    "            epoch\n",
    "        )\n",
    "\n",
    "        writer.add_scalars(\n",
    "            'metrics/psnr', {\n",
    "                f'train/{contrast_1}' : avg_cost[contrast_1][epoch, 2],\n",
    "                f'val/{contrast_1}' : avg_cost[contrast_1][epoch, 6],\n",
    "                f'train/{contrast_2}' : avg_cost[contrast_2][epoch, 2],\n",
    "                f'val/{contrast_2}' : avg_cost[contrast_2][epoch, 6],\n",
    "            }, \n",
    "            epoch\n",
    "        )\n",
    "\n",
    "        writer.add_scalars(\n",
    "            'metrics/nrmse', {\n",
    "                f'train/{contrast_1}' : avg_cost[contrast_1][epoch, 3],\n",
    "                f'val/{contrast_1}' : avg_cost[contrast_1][epoch, 7],\n",
    "                f'train/{contrast_2}' : avg_cost[contrast_2][epoch, 3],\n",
    "                f'val/{contrast_2}' : avg_cost[contrast_2][epoch, 7],\n",
    "            }, \n",
    "            epoch\n",
    "        )\n",
    "        \n",
    "        if True: ###opt###\n",
    "            writer.add_scalars(\n",
    "                'overall/metrics/ssim', {\n",
    "                    f'train' : avg_cost['overall'][epoch, 1],\n",
    "                    f'val' : avg_cost['overall'][epoch, 5],\n",
    "                }, \n",
    "                epoch\n",
    "            )\n",
    "\n",
    "            writer.add_scalars(\n",
    "                'overall/metrics/psnr', {\n",
    "                    f'train' : avg_cost['overall'][epoch, 2],\n",
    "                    f'val' : avg_cost['overall'][epoch, 6],\n",
    "                }, \n",
    "                epoch\n",
    "            )\n",
    "\n",
    "            writer.add_scalars(\n",
    "                'overall/metrics/nrmse', {\n",
    "                    f'train' : avg_cost['overall'][epoch, 3],\n",
    "                    f'val' : avg_cost['overall'][epoch, 7],\n",
    "                }, \n",
    "                epoch\n",
    "            )\n",
    "            \n",
    "            writer.add_scalars(\n",
    "                'overall/losses/l1', {\n",
    "                    f'train' : avg_cost['overall'][epoch, 0],\n",
    "                    f'val' : avg_cost['overall'][epoch, 4],\n",
    "                }, \n",
    "                epoch\n",
    "            )\n",
    "            \n",
    "    writer.add_text(\n",
    "        'parameters', \n",
    "        f'{count_parameters(model)} parameters'\n",
    "    )\n",
    "    \n",
    "    ###opts###\n",
    "    writer.add_hparams(\n",
    "        param_dict(0.001, 2, [6], [0], [0.06]), \n",
    "        {'overall/losses/l1':0}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b4aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(im_fs: torch.Tensor, im_us: torch.Tensor):\n",
    "    '''\n",
    "    @parameter im_us: undersampled image (2D)\n",
    "    @parameter im_fs: fully sampled image (2D)\n",
    "    should be on GPU device for fast computation\n",
    "    '''\n",
    "    \n",
    "    # use l1 loss between two images\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "    # can add more fancy loss functions here later\n",
    "    \n",
    "    return criterion(im_us, im_fs)\n",
    "\n",
    "def metrics(im_fs: torch.Tensor, im_us: torch.Tensor):\n",
    "    '''\n",
    "    @parameter im_us: undersampled image (2D)\n",
    "    @parameter im_fs: fully sampled image (2D)\n",
    "    should be on GPU device for fast computation\n",
    "    '''\n",
    "\n",
    "    # change to ndarray\n",
    "    im_us = transforms.tensor_to_complex_np(im_us.cpu().detach())\n",
    "    im_fs = transforms.tensor_to_complex_np(im_fs.cpu().detach())\n",
    "    \n",
    "    # convert complex nums to magnitude\n",
    "    im_us = np.absolute(im_us)\n",
    "    im_fs = np.absolute(im_fs)\n",
    "    \n",
    "    im_us = im_us.reshape(\n",
    "        (im_us.shape[2], im_us.shape[3])\n",
    "    )\n",
    "    \n",
    "    im_fs = im_fs.reshape(\n",
    "        (im_fs.shape[2], im_fs.shape[3])\n",
    "    )\n",
    "    \n",
    "    # psnr\n",
    "    psnr = skimage.metrics.peak_signal_noise_ratio(\n",
    "        im_fs, \n",
    "        im_us, \n",
    "        data_range = np.max(im_fs) - np.min(im_fs)\n",
    "    )\n",
    "    \n",
    "    #nrmse\n",
    "    nrmse = skimage.metrics.normalized_root_mse(im_fs, im_us)\n",
    "    \n",
    "    # ssim\n",
    "    # normalize 0 to 1\n",
    "    im_fs -= np.min(im_fs)\n",
    "    im_fs /= np.max(im_fs)\n",
    "    im_us -= np.min(im_us)\n",
    "    im_us /= np.max(im_us)\n",
    "    \n",
    "    ssim = skimage.metrics.structural_similarity(im_fs, im_us, data_range = 1)\n",
    "    \n",
    "    return ssim, psnr, nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d34ad2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=========== Universal Single-task Trainer =========== \n",
    "code modified from https://github.com/lorenmt/mtan/blob/master/im2im_pred/utils.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def single_task_trainer(\n",
    "    train_loader, val_loader,\n",
    "    train_ratios, val_ratios,\n",
    "    single_task_model, device, \n",
    "    optimizer, scheduler,\n",
    "    writer,\n",
    "    opt = 0, total_epochs=2 ###opt###\n",
    "):\n",
    "    \n",
    "    train_batch = len(train_loader)\n",
    "    val_batch = len(val_loader)\n",
    "    \n",
    "    best_val_loss = np.infty\n",
    "    \n",
    "    # contains info for all epochs and contrasts\n",
    "    avg_cost = {\n",
    "        contrast : np.zeros([total_epochs, 8])\n",
    "        for contrast in train_ratios.keys()\n",
    "    }\n",
    "    avg_cost['overall'] = np.zeros([total_epochs, 8])\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "        # contains info for single batch of a single epoch\n",
    "        cost = np.zeros(8, dtype = np.float32)\n",
    "\n",
    "        # train data\n",
    "        single_task_model.train()\n",
    "        train_dataset = iter(train_loader)\n",
    "    \n",
    "        for _ in range(train_batch):\n",
    "            kspace, mask, sens, im_fs, contrast = next(train_dataset)\n",
    "            contrast = contrast[0] # torch dataset loader returns as tuple\n",
    "            kspace, mask = kspace.to(device), mask.to(device)\n",
    "            sens, im_fs = sens.to(device), im_fs.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            _, im_us = single_task_model(kspace, mask, sens) # forward pass\n",
    "            loss = criterion(im_fs, im_us)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # L1 loss for now\n",
    "            cost[0] = loss.item() \n",
    "            # ssim, psnr, nrmse\n",
    "            cost[1], cost[2], cost[3] = metrics(im_fs, im_us)\n",
    "            \n",
    "            # update overall\n",
    "            avg_cost[contrast][epoch, :4] += cost[:4] / train_ratios[contrast]\n",
    "            avg_cost['overall'][epoch, :4] += cost[:4] / train_batch\n",
    "\n",
    "            \n",
    "        # validation data\n",
    "        single_task_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_dataset = iter(val_loader)\n",
    "\n",
    "            for val_idx in range(val_batch):\n",
    "                kspace, mask, sens, im_fs, contrast = next(val_dataset)\n",
    "                contrast = contrast[0]\n",
    "                kspace, mask = kspace.to(device), mask.to(device)\n",
    "                sens, im_fs = sens.to(device), im_fs.to(device)\n",
    "\n",
    "                _, im_us = single_task_model(kspace, mask, sens) # forward pass\n",
    "                loss = criterion(im_fs, im_us)\n",
    "                \n",
    "                # L1 loss for now\n",
    "                cost[4] = loss.item()\n",
    "                # ssim, psnr, nrmse\n",
    "                cost[5], cost[6], cost[7] = metrics(im_fs, im_us)\n",
    "                \n",
    "                # update overall\n",
    "                avg_cost[contrast][epoch, 4:] += cost[4:] / val_ratios[contrast]\n",
    "                avg_cost['overall'][epoch, 4:] += cost[4:] / val_batch\n",
    "                \n",
    "               # visualize reconstruction every few epochs\n",
    "                if val_idx == 18 and epoch % 1 == 0: ###opt###\n",
    "                    writer.add_figure(\n",
    "                        'recons', \n",
    "                        plot_quadrant(im_fs, im_us),\n",
    "                        epoch, close = True,\n",
    "                    )\n",
    "                \n",
    "                \n",
    "        # early stopping        \n",
    "        if avg_cost['overall'][epoch, 4] < best_val_loss:\n",
    "            best_val_loss = avg_cost['overall'][epoch, 4]\n",
    "            torch.save(single_task_model.state_dict(), 'models/best-val.pt') ###opt###\n",
    "            \n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'''\n",
    "        >Epoch: {epoch + 1:04d}\n",
    "        TRAIN: loss {avg_cost['overall'][epoch, 0]:.4f} | ssim {avg_cost['overall'][epoch, 1]:.4f} | psnr {avg_cost['overall'][epoch, 2]:.4f} | nrmse {avg_cost['overall'][epoch, 3]:.4f} \n",
    "        VAL: loss {avg_cost['overall'][epoch, 4]:.4f} | ssim {avg_cost['overall'][epoch, 5]:.4f} | psnr {avg_cost['overall'][epoch, 6]:.4f} | nrmse {avg_cost['overall'][epoch, 7]:.4f}\n",
    "        \n",
    "        ''')\n",
    "    \n",
    "        \n",
    "    # write to tensorboard\n",
    "    ###opt###\n",
    "    if True:\n",
    "        write_tensorboard(avg_cost, single_task_model, total_epochs, opt)   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2bb647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/dense/vliu/summer_dset/div_coronal_pd',\n",
       " '/mnt/dense/vliu/summer_dset/div_coronal_pd_fs']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets\n",
    "dataset_names = [\n",
    "    'div_coronal_pd',\n",
    "    'div_coronal_pd_fs',\n",
    "]\n",
    "\n",
    "basedirs = [\n",
    "    f'/mnt/dense/vliu/summer_dset/{dataset_name}'\n",
    "    for dataset_name in dataset_names\n",
    "]\n",
    "basedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7727218",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dloader = genDataLoader(\n",
    "    [f'{basedir}/Train' for basedir in basedirs], # choose randomly\n",
    "    [4, 4] # downsample\n",
    ")\n",
    "\n",
    "val_dloader = genDataLoader(\n",
    "    [f'{basedir}/Val' for basedir in basedirs], # choose randomly\n",
    "    [3, 3], # downsample\n",
    "    shuffle = False,\n",
    ")\n",
    "\n",
    "# other inputs to STL wrapper\n",
    "writer = SummaryWriter()\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "varnet = VarNet().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(varnet.parameters(),lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930fbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        >Epoch: 0001\n",
      "        TRAIN: loss 0.0526 | ssim 0.6879 | psnr 28.4583 | nrmse 0.2727 \n",
      "        VAL: loss 0.0463 | ssim 0.6956 | psnr 30.1173 | nrmse 0.2269\n",
      "        \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "single_task_trainer(\n",
    "    train_dloader[0], val_dloader[0], \n",
    "    train_dloader[1], val_dloader[1], # ratios dicts\n",
    "    varnet, device, \n",
    "    optimizer, scheduler,\n",
    "    writer,\n",
    "    opt = 0, total_epochs=3\n",
    ")\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a14d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# trying to get mr images onto tensorboard, unsuccessful\n",
    "###############################################\n",
    "\n",
    "dloader = iter(val_dloader[2])\n",
    "varnet = VarNet() \n",
    "varnet_gpu = varnet.to('cuda:3')\n",
    "Nepoch = 1\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(varnet_gpu.parameters(),lr=0.0002)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(Nepoch):\n",
    "    loss_epoch = 0\n",
    "    idx = 0\n",
    "    for kspace, mask, sens, im_true, contrast in dloader:\n",
    "        kspace_gpu, mask_gpu, sens_gpu, im_true_gpu = kspace.to('cuda:3'), mask.to('cuda:3'), sens.to('cuda:3'), im_true.to('cuda:3')\n",
    "        optimizer.zero_grad() \n",
    "        _, im_est_gpu = varnet_gpu(kspace_gpu,mask_gpu,sens_gpu)\n",
    "        loss = criterion(im_true_gpu, im_est_gpu)\n",
    "        loss.backward() # this performs the backprop\n",
    "        optimizer.step() # this performs the gradient update\n",
    "        loss_epoch += loss.item()\n",
    "        idx += 1\n",
    "        if idx == 17:\n",
    "            break\n",
    "    print('epoch:{}/{} Mean Loss: {}'.format(epoch, Nepoch, loss_epoch / len(dloader))) # report loss for end of the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97418578",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# trying to get mr images onto tensorboard, unsuccessful\n",
    "###############################################\n",
    "\n",
    "%matplotlib inline\n",
    "# Let's look at the final produced image\n",
    "im_est = transforms.tensor_to_complex_np(im_est_gpu.cpu().detach())\n",
    "im_true = transforms.tensor_to_complex_np(im_true_gpu.cpu().detach())\n",
    "\n",
    "pl.ImagePlot(im_est) # this is est image\n",
    "pl.ImagePlot(im_true) # this is true image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc6fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
