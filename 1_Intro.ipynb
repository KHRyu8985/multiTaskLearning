{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sigpy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "import skimage\n",
    "from fastmri.evaluate import ssim\n",
    "\n",
    "import sigpy.plot as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the dset : /mnt/dense/kanghyun/summer_dset\n",
    "# There are 4 datasets (different contrast or anatomy)\n",
    "print('Datasets: ',os.listdir('/mnt/dense/kanghyun/summer_dset'))\n",
    "print('Inside Coronal-PD directory: ',os.listdir('/mnt/dense/kanghyun/summer_dset/div_coronal_pd'))\n",
    "print('Inside Train directory: ',os.listdir('/mnt/dense/kanghyun/summer_dset/div_coronal_pd/Train'))\n",
    "\n",
    "basedir = '/mnt/dense/kanghyun/summer_dset/div_coronal_pd/Train' # make this as base directory and move on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading h5 file\n",
    "# h5 file is a format to store a large size array, which can not be accessed fully with RAM\n",
    "with h5py.File(os.path.join(basedir, 'rawdata_14.h5'),'r') as hr:\n",
    "    print(list(hr.keys())) # What is inside the h5 file\n",
    "    kspace = hr['kspace'][:] # saving the array to numpy (RAM)\n",
    "    sens = hr['sens'][:]\n",
    "\n",
    "print(kspace.shape, sens.shape) # order (nslices, nCoils, nX, nY)\n",
    "# Note that nX is much bigger than nY (because for Cartesian, sampling in nX doesn't affect overall scan time)\n",
    "# Scan time for the dataset : TR x nY. TR affects image contrast (small TR -> T1 weighting, large TR -> PD / T2 weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at the kspace\n",
    "\n",
    "pl.ImagePlot(kspace) # Visualization of kspace in original space\n",
    "pl.ImagePlot(kspace**0.2) # Visualization of kspace in approx. log scale (much better to visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.ImagePlot(kspace**0.2, z=1) # Let's look at multi-coil kspace, z=1 means visualizing grid on the axis =1\n",
    "# ith kspace corresponds to fft(true_image * coil_sensitivity_i) \n",
    "\n",
    "im_coil = sp.ifft(kspace, axes=(-1,-2)) # Let's ifft kspace to get coil image\n",
    "\n",
    "pl.ImagePlot(im_coil, z=1) # Here now you can see each images correspond to true_image * coil_sensitivity\n",
    "pl.ImagePlot(sens, z=1) # Look at the sensitivity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are mainly two ways to combine the multi-coil images\n",
    "# 1. coils are designed to be symetrically distributed around the object, so usually root-sum-of squares can get sufficient estimates\n",
    "\n",
    "im_rss = np.sqrt((im_coil * np.conj(im_coil)).sum(axis=1)) # np.conj because MR images are complex\n",
    "print('RSS combined', im_rss.shape)\n",
    "pl.ImagePlot(im_rss) \n",
    "\n",
    "# 2. Coil sensitivity maps can be scanned or estimated (i.e. ESPIRIT, JSENSE, etc.) and used to combine  \n",
    "\n",
    "im_sense = np.sum(im_coil * np.conj(sens), axis=1)\n",
    "pl.ImagePlot(im_sense) \n",
    "\n",
    "# (optional) Refer to https://users.fmrib.ox.ac.uk/~mchiew/docs/SENSE_tutorial.html, It's in MATLAB but covers SENSE reconstruction, gfactor maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of Undersampled acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmri.data import subsample, transforms\n",
    "\n",
    "R = 4\n",
    "mask_func = subsample.EquispacedMaskFunc(\n",
    "                            center_fractions=[0.06],\n",
    "                            accelerations=[R]) # This function generates an equispaced sampling mask generator\n",
    "# help(subsample.EquispacedMaskFunc) # This is the description (uncomment this)\n",
    "\n",
    "mask = mask_func(list(kspace.shape) + [1])[...,0] # trick because undersampling is in axis -1\n",
    "mask = mask.numpy()\n",
    "print(mask.shape)\n",
    "\n",
    "kspace_us = kspace * mask \n",
    "pl.ImagePlot(kspace_us ** 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_us_coil = sp.ifft(kspace_us, axes=(-1,-2)) # Let's try to reconstruct with the same process\n",
    "im_us_sense = np.sum(im_us_coil * np.conj(sens), axis=1)\n",
    "\n",
    "pl.ImagePlot(im_us_sense) # Now we get a weird aliased image\n",
    "\n",
    "# Typically SENSE/GRAPPA (Parallel Imaging) method can recover x2 accelerations, \n",
    "# Parallel Imaging + Compressed Sensing (PI-CS) can recover x2-4 accelerations\n",
    "# Deep Learning can recover up to x4-6 accelerations\n",
    "# The final objective will be (im_us_sense + kspace_us + sensivitiy) ==> Deep Learning Recon ==> im_sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, let's look at PI-CS reconstruction method\n",
    "# PI-CS method performs better with random-sampling so the result may be worse than it actually is\n",
    "# Refer to https://github.com/mikgroup/sigpy-mri-tutorial/blob/master/03-building-an-l1-wavelet-recon-app.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PI-CS solves the following minimization problem:\n",
    "$$\\min_x \\frac{1}{2} \\| \\underbrace{P F S }_{A} x - y \\|_2^2 + \\lambda \\|W x \\|_1$$\n",
    "Where P is the sampling operator, F is the Fourier Transform operator, S is the sensitivity map operator, W is the wavelet transform operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigpy.mri.app import L1WaveletRecon\n",
    "\n",
    "y = kspace_us[17] # select 17th slice\n",
    "mps = sens[17]\n",
    "\n",
    "img = L1WaveletRecon(y, mps, lamda = 0.05).run() # lamda is the regularizaition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.05\n",
    "pl.ImagePlot(img, title = f'lambda = {lambda_}') # This is the reconstructed result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task to do : 1. How does the reconstructed image looks for different lambda values\n",
    "# 2. What is the quantitative score (nRMSE, SSIM) for the above image? Can you calculate mean + std for the score for the images in Test \n",
    "# Please try this demo for other datasets and ask questions on Notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task 1\n",
    "lambdas = [0.001, 0.01, 0.03, 0.05, 0.07, 0.1, 0.2]\n",
    "for lambda_ in lambdas:\n",
    "    img = L1WaveletRecon(y, mps, lamda = lambda_).run() # lamda is the regularizaition\n",
    "    pl.ImagePlot(img, title = f'lambda = {lambda_}') # This is the reconstructed result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\lambda$ is too low, the image looks noisy. When $\\lambda$ is too high, the image looks overly smooth and seems to miss out on textural details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2 ssim and nrmse for slice 17\n",
    "# convert complex nums to magnitude\n",
    "im_true = np.absolute(im_sense)[17]\n",
    "im_us = np.absolute(img)\n",
    "im_true = np.expand_dims(im_true, axis = 0)\n",
    "im_us = np.expand_dims(im_us, axis = 0)\n",
    "\n",
    "print (f'SSIM: {ssim(im_true, im_us)}')\n",
    "print (f'nRMSE: {skimage.metrics.normalized_root_mse(im_true, im_us)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2:\n",
    "# use custom dataset class from 2_dataloader.ipynb\n",
    "# change center_fractions to 0.06 and accelerations to 4\n",
    "# to match current problem\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, root, center_fractions=[0.06], accelerations=[4]):\n",
    "        self.examples = []\n",
    "        Files = list(pathlib.Path(root).glob('*.h5'))\n",
    "        for fname in Files:\n",
    "            h5file = h5py.File(fname, 'r')\n",
    "            kspace = h5file['kspace']\n",
    "            nsl = kspace.shape[0] # get number of slices\n",
    "            self.examples += [(fname, sl) for sl in range(nsl)]\n",
    "        \n",
    "        self.mask_func = subsample.EquispacedMaskFunc(center_fractions=center_fractions, accelerations=accelerations)\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    def __getitem__(self, idx):\n",
    "        fname, sl = self.examples[idx]\n",
    "        with h5py.File(fname, 'r') as hr:\n",
    "            kspace, sens = hr['kspace'][sl], hr['sens'][sl]\n",
    "        kspace = kspace / 10 # divide by 10 because the values are too large\n",
    "        im_coil = sp.ifft(kspace, axes=[1, 2])\n",
    "        im_true = np.sum(im_coil * np.conj(sens), axis=0) # im_true is the fully sampled reconned image\n",
    "        \n",
    "        mask = self.mask_func(list(im_true.shape) + [1])[...,0]                              \n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        masked_kspace = kspace * mask # undersampled kspace\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        \n",
    "        # Now transform everything to tensor. The complex kspace will be changed to [real, imag] in the final axis\n",
    "        masked_kspace = transforms.to_tensor(masked_kspace) \n",
    "        mask = transforms.to_tensor(mask)\n",
    "        sens = transforms.to_tensor(sens)\n",
    "        im_true = np.expand_dims(im_true, axis=0)\n",
    "        im_true = transforms.to_tensor(im_true)\n",
    "                        \n",
    "        return masked_kspace, mask.byte(), sens, im_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "dataset = 'Test'\n",
    "basedir = f'/mnt/dense/kanghyun/summer_dset/div_coronal_pd/{dataset}'\n",
    "dset = MRIDataset(basedir)\n",
    "\n",
    "ssims = np.zeros(len(dset))\n",
    "nrmses = np.zeros(len(dset))\n",
    "\n",
    "for iidx, (kspace_us, _, sens, im_true) in enumerate(dset):\n",
    "    # make ndarray for wavelet \n",
    "    kspace_us = transforms.tensor_to_complex_np(kspace_us)\n",
    "    sens = transforms.tensor_to_complex_np(sens)\n",
    "    im_true = transforms.tensor_to_complex_np(im_true)\n",
    "    \n",
    "    # reconstruct undersampled 2D img w wavelet\n",
    "    im_us = L1WaveletRecon(\n",
    "        kspace_us, \n",
    "        sens, \n",
    "        lamda = 0.05\n",
    "    ).run()\n",
    "    \n",
    "    \n",
    "    # convert complex nums to magnitude\n",
    "    im_true = np.absolute(im_true)\n",
    "    im_us = np.absolute(im_us)\n",
    "    im_us = np.expand_dims(im_us, axis = 0) # expand bc need 3 dims\n",
    "\n",
    "    ssims[iidx] = ssim(im_true, im_us)\n",
    "    nrmses[iidx] = skimage.metrics.normalized_root_mse(im_true, im_us)\n",
    "    \n",
    "    print (f'SSIM {iidx}: {ssim(im_true, im_us)}')\n",
    "    print (f'nRMSE {iidx}: {skimage.metrics.normalized_root_mse(im_true, im_us)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mean ssim: {np.mean(ssims)}')\n",
    "print(f'std ssim: {np.std(ssims)}')\n",
    "print(f'mean nrmse: {np.mean(nrmses)}')\n",
    "print(f'std nrmse: {np.std(nrmses)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SSIM is $0.7955 \\pm 0.0867$; the nRMSE is $0.1376 \\pm 0.0690$ for Wavelet-based reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for other datasets, not as verbose and put into a function\n",
    "# Task 2\n",
    "\n",
    "dataset_names = ['div_coronal_pd', 'div_coronal_pd_fs', 'div_axial_t2', 'div_sagittal_t2',]\n",
    "dataset_types = ['Train', 'Test', 'Val',]\n",
    "basedirs = [\n",
    "    f'/mnt/dense/kanghyun/summer_dset/{dataset_name}/{dataset_type}'\n",
    "    for dataset_name in dataset_names\n",
    "    for dataset_type in dataset_types\n",
    "]\n",
    "basedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def metrics_wavelet(basedir):\n",
    "    dset = MRIDataset(basedir)\n",
    "\n",
    "    ssims = np.zeros(len(dset))\n",
    "    nrmses = np.zeros(len(dset))\n",
    "\n",
    "    for iidx, (kspace_us, _, sens, im_true) in enumerate(dset):\n",
    "        # make ndarray for wavelet \n",
    "        kspace_us = transforms.tensor_to_complex_np(kspace_us)\n",
    "        sens = transforms.tensor_to_complex_np(sens)\n",
    "        im_true = transforms.tensor_to_complex_np(im_true)\n",
    "\n",
    "        # reconstruct undersampled 2D img w wavelet\n",
    "        im_us = L1WaveletRecon(\n",
    "            kspace_us, \n",
    "            sens, \n",
    "            lamda = 0.05\n",
    "        ).run()\n",
    "\n",
    "        # convert complex nums to magnitude\n",
    "        im_true = np.absolute(im_true)\n",
    "        im_us = np.absolute(im_us)\n",
    "        im_us = np.expand_dims(im_us, axis = 0) # expand bc need 3 dims\n",
    "\n",
    "        ssims[iidx] = ssim(im_true, im_us)\n",
    "        nrmses[iidx] = skimage.metrics.normalized_root_mse(im_true, im_us)\n",
    "\n",
    "    print(f'dataset: {basedir}')\n",
    "    print(f'mean ssim: {np.mean(ssims)}')\n",
    "    print(f'std ssim: {np.std(ssims)}')\n",
    "    print(f'mean nrmse: {np.mean(nrmses)}')\n",
    "    print(f'std nrmse: {np.std(nrmses)}')\n",
    "    \n",
    "\n",
    "    with open('metrics_wavelet.csv', 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([basedir, np.mean(ssims), np.std(ssims), np.mean(nrmses), np.std(nrmses)])\n",
    "    file.close()\n",
    "\n",
    "    \n",
    "with open('metrics_wavelet.csv', 'a') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Dataset\", \"SSIM mean\", \"SSIM std\", \"nRMSE mean\", \"nRMSE std\"])\n",
    "file.close()\n",
    "\n",
    "for basedir in basedirs:\n",
    "    metrics_wavelet(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "568cf607fb1663ae5f6ca9795a3e49ea7987a37e32b3101a93f155d5c8f93f18"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
