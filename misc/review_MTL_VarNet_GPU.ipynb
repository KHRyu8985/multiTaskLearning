{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from dloader import genDataLoader \n",
    "import sigpy as sp\n",
    "import sigpy.plot as pl\n",
    "from fastmri.data import transforms\n",
    "from collections import Counter\n",
    "import torch\n",
    "from icecream import ic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import fastmri\n",
    "from fastmri.models.varnet import NormUnet\n",
    "\n",
    "import logging\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"MTL_Loss_iteration.txt\",\n",
    "                level=logging.DEBUG,\n",
    "                format='%(levelname)s: %(asctime)s %(message)s',\n",
    "                datefmt='%m/%d/%Y %I:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     49
    ]
   },
   "outputs": [],
   "source": [
    "class VarNetBlockShared(nn.Module):\n",
    "    \"\"\"\n",
    "    Hard-coded for only two contrasts\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.eta1 = nn.Parameter(torch.ones(1)) # for eta1\n",
    "        self.eta2 = nn.Parameter(torch.ones(1)) # for eta2\n",
    "        \n",
    "    def sens_expand(self, x: torch.Tensor, sens_maps: torch.Tensor) -> torch.Tensor:\n",
    "        return fastmri.fft2c(fastmri.complex_mul(x, sens_maps)) # F*S operator\n",
    "\n",
    "    def sens_reduce(self, x: torch.Tensor, sens_maps: torch.Tensor) -> torch.Tensor:\n",
    "        x = fastmri.ifft2c(x)\n",
    "        return fastmri.complex_mul(x, fastmri.complex_conj(sens_maps)).sum(\n",
    "            dim=1, keepdim=True\n",
    "        ) # S^H * F^H operator\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        current_kspace: torch.Tensor,\n",
    "        ref_kspace: torch.Tensor,\n",
    "        mask: torch.Tensor,\n",
    "        sens_maps: torch.Tensor,\n",
    "        int_contrast: int\n",
    "    ) -> torch.Tensor:\n",
    "        '''\n",
    "        note that contrast is not str, but rather int index of opt.datasets\n",
    "        this is implemented in the VarNet portion\n",
    "        '''\n",
    "\n",
    "        mask = mask.bool()\n",
    "        zero = torch.zeros(1, 1, 1, 1, 1).to(current_kspace)\n",
    "        if int_contrast == 0:\n",
    "            soft_dc = torch.where(mask, current_kspace - ref_kspace, zero) * self.eta1\n",
    "        else:\n",
    "            soft_dc = torch.where(mask, current_kspace - ref_kspace, zero) * self.eta2\n",
    "\n",
    "        model_term = self.sens_expand(\n",
    "            self.model(\n",
    "                self.sens_reduce(current_kspace, sens_maps)), \n",
    "                sens_maps\n",
    "        )\n",
    "\n",
    "        return current_kspace - soft_dc - model_term\n",
    "    \n",
    "    \n",
    "class VarNetBlockUnshared(nn.Module):\n",
    "\n",
    "    def __init__(self, model1: nn.Module, model2:nn.Module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model1 = model1\n",
    "        self.eta1 = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "        self.model2 = model2\n",
    "        self.eta2 = nn.Parameter(torch.ones(1))\n",
    " \n",
    "    def sens_expand(self, x: torch.Tensor, sens_maps: torch.Tensor) -> torch.Tensor:\n",
    "        return fastmri.fft2c(fastmri.complex_mul(x, sens_maps)) # F*S operator\n",
    "\n",
    "    def sens_reduce(self, x: torch.Tensor, sens_maps: torch.Tensor) -> torch.Tensor:\n",
    "        x = fastmri.ifft2c(x)\n",
    "        return fastmri.complex_mul(x, fastmri.complex_conj(sens_maps)).sum(\n",
    "            dim=1, keepdim=True\n",
    "        ) # S^H * F^H operator\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        current_kspace: torch.Tensor,\n",
    "        ref_kspace: torch.Tensor,\n",
    "        mask: torch.Tensor,\n",
    "        sens_maps: torch.Tensor,\n",
    "        int_contrast: int\n",
    "    ) -> torch.Tensor:\n",
    "        '''\n",
    "        note that contrast is not str, but rather int index of opt.datasets\n",
    "        this is implemented in the VarNet portion\n",
    "        '''\n",
    "        assert int_contrast == 0 or int_contrast == 1, 'Only two contrasts are allowed'\n",
    "    \n",
    "        mask = mask.bool()\n",
    "        zero = torch.zeros(1, 1, 1, 1, 1).to(current_kspace)\n",
    "        \n",
    "        if int_contrast == 0:\n",
    "            soft_dc = torch.where(mask, current_kspace - ref_kspace, zero) * self.eta1\n",
    "            model_term = self.sens_expand(\n",
    "            self.model1(\n",
    "                self.sens_reduce(current_kspace, sens_maps)), \n",
    "                sens_maps\n",
    "            )\n",
    "            \n",
    "            return current_kspace - soft_dc - model_term\n",
    "        else:\n",
    "            soft_dc = torch.where(mask, current_kspace - ref_kspace, zero) * self.eta2\n",
    "            model_term = self.sens_expand(\n",
    "            self.model2(\n",
    "                self.sens_reduce(current_kspace, sens_maps)), \n",
    "                sens_maps\n",
    "            )\n",
    "            \n",
    "            return current_kspace - soft_dc - model_term\n",
    "\n",
    "class VarNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A full variational network model.\n",
    "\n",
    "    This model applies a combination of soft data consistency with a U-Net\n",
    "    regularizer. To use non-U-Net regularizers, use VarNetBock.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_shared: int = 3,  # unshared shared unshared shared unshared shared (this is 6 unrolls)\n",
    "        num_final_unshared: int = 4,  # multi head blocks\n",
    "        chans: int = 12,\n",
    "        pools: int = 4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared_cascades = nn.ModuleList()\n",
    "        self.unshared_cascades = nn.ModuleList()\n",
    "\n",
    "        for it in range(num_shared):\n",
    "            module_name = 'Shared' + str(it)\n",
    "            self.shared_cascades.add_module(\n",
    "                module_name, VarNetBlockShared(NormUnet(chans, pools)))\n",
    "            module_name = 'UnShared' + str(it)\n",
    "            self.shared_cascades.add_module(\n",
    "                module_name,\n",
    "                VarNetBlockUnshared(NormUnet(chans, pools),\n",
    "                                    NormUnet(chans, pools)))\n",
    "\n",
    "        for it in range(num_final_unshared): # This is final multiple heads\n",
    "            module_name = 'FinalUnShared' + str(it)\n",
    "            self.unshared_cascades.add_module(\n",
    "                module_name,\n",
    "                VarNetBlockUnshared(NormUnet(chans, pools),\n",
    "                                    NormUnet(chans, pools)))\n",
    "\n",
    "    def forward(self, masked_kspace: torch.Tensor, mask: torch.Tensor,\n",
    "                esp_maps: torch.Tensor, int_contrast:int) -> torch.Tensor:\n",
    "        kspace_pred = masked_kspace.clone()\n",
    "\n",
    "        for cascade in self.shared_cascades:\n",
    "            kspace_pred = cascade(kspace_pred, masked_kspace, mask, esp_maps, int_contrast)\n",
    "        for cascade in self.unshared_cascades:\n",
    "            kspace_pred = cascade(kspace_pred, masked_kspace, mask, esp_maps, int_contrast)\n",
    "        \n",
    "        im_coil = fastmri.ifft2c(kspace_pred)\n",
    "        im_comb = fastmri.complex_mul(im_coil, fastmri.complex_conj(esp_maps)).sum(\n",
    "            dim=1, keepdim=True\n",
    "        )\n",
    "        \n",
    "        return im_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'div_coronal_pd_fs',\n",
    "    'div_coronal_pd'\n",
    "]\n",
    "\n",
    "datadir = '/mnt/dense/vliu/summer_dset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| basedirs: ['/mnt/dense/vliu/summer_dset/div_coronal_pd_fs',\n",
      "               '/mnt/dense/vliu/summer_dset/div_coronal_pd']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/mnt/dense/vliu/summer_dset/div_coronal_pd_fs',\n",
       " '/mnt/dense/vliu/summer_dset/div_coronal_pd']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basedirs = [\n",
    "    os.path.join(datadir, dataset)\n",
    "    for dataset in datasets\n",
    "]\n",
    "ic(basedirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dloader = genDataLoader(\n",
    "    ['/mnt/dense/vliu/summer_dset/div_coronal_pd_fs/Train','/mnt/dense/vliu/summer_dset/div_coronal_pd/Val'],\n",
    "    [0, 0], # Let's not downsample anything for a start \n",
    "    center_fractions = [0.05, 0.06, 0.07, 0.08],\n",
    "    accelerations = [4, 5, 6],\n",
    "    num_workers= 16,\n",
    "    shuffle = True,\n",
    "    stratified = 1, method = 'upsample'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnet = VarNet(3,4,12,4) # very simple varnet for reviewing (3x2 + 3 = 9 unrolls)\n",
    "varnet = varnet.cuda()\n",
    "criterion = nn.L1Loss() # simple loss func\n",
    "optimizer = torch.optim.Adam(varnet.parameters(),lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(100): \n",
    "    # for 100 epochs in test set\n",
    "    # See if training loss gets smaller or not\n",
    "    train_dataset = iter(train_dloader[0])\n",
    "    loss1 = 0\n",
    "    loss2 = 0\n",
    "    \n",
    "    for kspace, mask, esp, im_fs, contrast in train_dataset:\n",
    "        kspace, mask = kspace.cuda(), mask.cuda()\n",
    "        esp, im_fs = esp.cuda(), im_fs.cuda()\n",
    "\n",
    "        if contrast[0] == 'div_coronal_pd_fs': # This is contrast 0\n",
    "            input_contrast = 0\n",
    "        else:\n",
    "            input_contrast = 1\n",
    "\n",
    "        pred = varnet(kspace, mask, esp, input_contrast)\n",
    "        pred = transforms.complex_center_crop(pred, tuple(im_fs.shape[2:4]))\n",
    "\n",
    "        loss = criterion(pred, im_fs)\n",
    "        loss.backward()\n",
    "        \n",
    "        if epoch > 1: # ignore first epoch\n",
    "            if input_contrast == 0:\n",
    "                loss1 += loss.item()\n",
    "            else:\n",
    "                loss2 += loss.item()\n",
    "        \n",
    "        if input_contrast == 1:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "    if epoch >1:\n",
    "        loss1 /= len(train_dataset)\n",
    "        loss2 /= len(train_dataset)\n",
    "\n",
    "        logging.info('Epoch {} Loss1: {}'.format(epoch, loss1))\n",
    "        logging.info('Epoch {} Loss2: {}'.format(epoch, loss2))\n",
    "        torch.save(varnet.state_dict(), 'MTL_weight.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dloader = genDataLoader(\n",
    "    [f'{basedir}/Test' for basedir in basedirs],\n",
    "    [0, 0], # Let's not downsample anything for a start \n",
    "    center_fractions = [0.06],\n",
    "    accelerations = [6],\n",
    "    num_workers= 16,\n",
    "    shuffle = True,\n",
    "    stratified = 1, method = 'upsample'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = iter(test_dloader[0]) # dloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspace1, mask1, esp1, im_fs1, contrast1 = next(testloader)\n",
    "if contrast1[0] == 'div_coronal_pd_fs': # This is contrast 0\n",
    "    input_contrast = 0\n",
    "else:\n",
    "    input_contrast = 1\n",
    "ic(input_contrast) # This is coronal_pd_fs (contrast #0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    kspace, mask = kspace1.cuda(), mask1.cuda()\n",
    "    esp, im_fs = esp1.cuda(), im_fs1.cuda()\n",
    "\n",
    "    pred = varnet(kspace, mask, esp, input_contrast)\n",
    "    pred = transforms.complex_center_crop(pred, tuple(im_fs.shape[2:4]))\n",
    "    print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(pred, im_fs)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now look at the image\n",
    "pred1_numpy = transforms.tensor_to_complex_np(pred.cpu())\n",
    "im_fs1_numpy = transforms.tensor_to_complex_np(im_fs1.cpu())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10,10))\n",
    "ax1.imshow(np.abs(pred1_numpy.squeeze()), cmap='gray')\n",
    "ax2.imshow(np.abs(im_fs1_numpy.squeeze()), cmap='gray')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "568cf607fb1663ae5f6ca9795a3e49ea7987a37e32b3101a93f155d5c8f93f18"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
